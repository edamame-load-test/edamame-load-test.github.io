<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-case-study">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.3.1">
<title data-rh="true">Case Study | Edamame</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://edamame-load-test.github.io/img/edamame-social-card.png"><meta data-rh="true" name="twitter:image" content="https://edamame-load-test.github.io/img/edamame-social-card.png"><meta data-rh="true" property="og:url" content="https://edamame-load-test.github.io/docs/case-study"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Case Study | Edamame"><meta data-rh="true" name="description" content="1. What is Edamame?"><meta data-rh="true" property="og:description" content="1. What is Edamame?"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://edamame-load-test.github.io/docs/case-study"><link data-rh="true" rel="alternate" href="https://edamame-load-test.github.io/docs/case-study" hreflang="en"><link data-rh="true" rel="alternate" href="https://edamame-load-test.github.io/docs/case-study" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.4bf5a4e4.css">
<link rel="preload" href="/assets/js/runtime~main.75d44608.js" as="script">
<link rel="preload" href="/assets/js/main.3bbd35a5.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.jpg" alt="Edamame Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.jpg" alt="Edamame Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Edamame</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/case-study">Case Study</a><a class="navbar__item navbar__link" href="/docs/docs">Docs</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><main class="docMainContainer_gTbr docMainContainerEnhanced_Uz_u"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Case Study</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-what-is-edamame">1. What is Edamame?<a href="#1-what-is-edamame" class="hash-link" aria-label="Direct link to 1. What is Edamame?" title="Direct link to 1. What is Edamame?">​</a></h2><p>Edamame is an open-source, distributed load testing framework, optimized for real-time collaboration apps that use both HTTP and WebSockets. It comes with a CLI and React GUI that enables developers to easily self-host cloud-based architecture on AWS. Edamame supports tests of up to 200k virtual users, visualizes data in near real-time, and includes a stop functionality allowing developers to end their tests early.</p><p>Creating a load-tester with these features comes with a unique set of challenges:</p><ul><li><strong>Coordinating distributed tests</strong>: The scale of Edamame load tests necessitated expanding into a distributed architecture while ensuring that the load tests remained synchronized.</li><li><strong>Processing 1M+ data points/second (in near real time)</strong>: Large load tests on Edamame can generate 1M+ metrics per second, all of which need to be processed and displayed in near real time.</li><li><strong>Extracting useful insights</strong>: When testing applications that use both HTTP and WebSockets, it’s important to extract metrics that provide insights into the application’s performance across both protocols.</li></ul><p>In the sections that follow, we’ll explore how Edamame offers an easy-to-use, plug-and-play solution to the above challenges.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-background-load-testing">2. Background: Load testing<a href="#2-background-load-testing" class="hash-link" aria-label="Direct link to 2. Background: Load testing" title="Direct link to 2. Background: Load testing">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="a-what-is-load-testing">a. What is load testing?<a href="#a-what-is-load-testing" class="hash-link" aria-label="Direct link to a. What is load testing?" title="Direct link to a. What is load testing?">​</a></h3><p>What happens when a web application gets more traffic than anticipated? Can the underlying infrastructure handle the traffic? Does the application slow down? Or—worst case scenario—does the application crash?</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" width="400" class="img_ev3q"><p>Figure 2.1: Tweet of Ticketmaster going down due to high traffic</p></div><p>Experiencing slow websites, downtime, or other issues due to excessive traffic is a frustrating reality for many internet users. Whether it&#x27;s a popular online sales event like Black Friday or a highly anticipated concert, the surge of visitors to a website can cause it to slow down or even crash. Ticketmaster found out just how bad things could get when 14 million users tried to buy Taylor Swift tickets and crashed their site<sup id="fnref-1"><a href="#fn-1" class="footnote-ref">1</a></sup>.</p><p>To ensure their application can handle this kind of situation, developers re-create high-traffic scenarios by performing load tests. <strong>Load testing</strong> is the process of simulating realistic end-user behavior in large volumes and measuring how the target server responds. In a load test, a number of programmatically generated &quot;virtual users&quot; are automated to interact with the target server in predefined patterns. This process helps developers identify performance bottlenecks within a system and ensures that user experience won&#x27;t be negatively impacted, even under heavy strain.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 2.2: A simple load tester (API Blaster)</p></div><p>One way to perform a basic load test is to use an HTTP benchmarking tool, like <code>wg/wrk</code>.<sup id="fnref-2"><a href="#fn-2" class="footnote-ref">2</a></sup> This involves sending frequent HTTP requests to a target endpoint to simulate large amounts of traffic and monitoring the system’s response.</p><div class="language-txt codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_Ktv7">wrk command</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-txt codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">wrk --connections=400 --duration=30s http://127.0.0.1:8080/index.html</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>While this is a simple approach to load testing, more complexities arise when a developer tries to comprehensively test a multifaceted application. Depending on the developer&#x27;s requirements, there can be many considerations involved in building a load tester.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="b-considerations-when-building-a-load-tester">b. Considerations when building a load tester<a href="#b-considerations-when-building-a-load-tester" class="hash-link" aria-label="Direct link to b. Considerations when building a load tester" title="Direct link to b. Considerations when building a load tester">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="i-scale">i. Scale<a href="#i-scale" class="hash-link" aria-label="Direct link to i. Scale" title="Direct link to i. Scale">​</a></h4><p>Running load tests locally is limiting. It&#x27;s difficult to simulate thousands of separate users on a single host. For example, a load testing tool with a fairly low memory footprint used on a 2-core CPU host with 8GB of RAM can generate a maximum of about 6k virtual users.<sup id="fnref-3"><a href="#fn-3" class="footnote-ref">3</a></sup></p><p>There are three main limiting factors to load testing on a local machine:</p><ul><li><strong>CPU</strong>: The CPU is heavily utilized in a load test. If it is not powerful enough, it can become a bottleneck, slowing down the test and limiting the number of virtual users that can be simulated.</li><li><strong>Memory</strong>: Load tests running on a single host cannot generate more virtual users than the RAM will support. Load tests often use 1 - 20 MB per virtual user, so even with only 1000 VUs, developers might need up to 20GB of RAM to run that load test.<sup id="fnref-4"><a href="#fn-4" class="footnote-ref">4</a></sup></li><li><strong>Network</strong>: If the network throughput is too low, the load test may not accurately simulate the real-world conditions of user traffic, resulting in inaccurate or unreliable test results. For instance, in the example host above the maximum network bandwidth is 10GB.<sup id="fnref-5"><a href="#fn-5" class="footnote-ref">5</a></sup></li></ul><p>If local resources do not allow a developer to reach the desired number of virtual users, then it&#x27;s necessary to run a distributed load test. In a <strong>distributed load test</strong> multiple hosts generate load. The hosts which create virtual users and run the test are often known as &quot;load generator nodes&quot; or &quot;test runner nodes&quot;. These can be horizontally scaled to support the number of virtual users required.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 2.3: A distributed load test where multiple hosts are spinning up virtual users to generate load, and collect response data</p></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="ii-protocol">ii. Protocol<a href="#ii-protocol" class="hash-link" aria-label="Direct link to ii. Protocol" title="Direct link to ii. Protocol">​</a></h4><p>Protocol refers to the type of traffic being generated to interact with the target server. As HTTP is the main protocol of the web, HTTP is frequently used when load testing web applications. However, there are many other protocols as well, some of which are used to communicate with users and some of which are used to facilitate communication between application components internally.</p><p>If developers want to test their entire system comprehensively, they need to ensure load tests simulate all the protocols that underlie their system.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="iii-metrics">iii. Metrics<a href="#iii-metrics" class="hash-link" aria-label="Direct link to iii. Metrics" title="Direct link to iii. Metrics">​</a></h4><p>Metrics are quantitative measures used to evaluate the performance of the web application. Generally speaking, there are two kinds of metrics that can be used to evaluate performance:</p><ul><li><strong>Server-side metrics</strong> measure the performance of the system from the server’s perspective. They include things like CPU usage, memory consumption, and network bandwidth.</li><li><strong>Client-side metrics</strong> provide insight into the end-user’s experience. They include things like HTTP response time, a measure of latency.</li></ul><p>Load tests are focused on understanding how the user experience changes under heavy load. As such, developers typically track client-side metrics when performing load tests. Server-side metrics, on the other hand, are often obtained by system monitoring tools outside the load test’s purview.</p><p>The types of metrics that are collected depend on the target application’s use case. For web applications that use HTTP, metrics like HTTP response time and failed HTTP requests are useful. HTTP response time informs developers how long it takes their system to respond to user requests, while failed HTTP requests count the number of times user requests do not receive a response. An increase in either of these values could indicate that the target system is starting to regress.</p><p>In general, load testing tends to produce a large quantity of “noisy” data, meaning it lacks consistency and reliability which makes it difficult to discern trends. This is because load testing data contains wide variations, some of which can be attributed to factors unrelated to an application’s performance. For example, network latency can come from areas outside of an application’s control, and contributes to HTTP response time.</p><p>To deal with this, developers perform data smoothing, which involves some kind of data aggregation. One approach to aggregation is to take an average. However, the same factors that make data noisy means that the average isn’t necessarily indicative of the majority of users’ experience.</p><p>For example, both scenarios below have an average HTTP response time of two seconds, which represents a poor user experience. However, the experience of the majority of users across these scenarios is not the same. In scenario A, the majority of users have acceptable HTTP response times of less than half a second. In this case, a single outlier is skewing the average result. In scenario B, however, all users have an HTTP response time greater than one second, indicating a poor user experience across the board.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 2.4: The “average” is often not descriptive of the user experience</p></div><p>Because the average is often unreliable, it can be more effective to look at percentiles. For example, if the 50th percentile, also known as the median, is 500ms then developers know 50% of response times were lower than 500ms, and 50% were higher. Looking at the “tail end” (&gt;90%) of percentiles can provide information about the worst-case performance scenarios. If the 90th percentile of response times is 1,800ms, it means that 10% of users have response times greater than 1,800ms. The experience of these users would not be apparent when looking at the median alone.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 2.3: Right-skewed distribution of HTTP response times</p></div><p>Therefore, it’s important to consider both the metrics that are being collected by the load test as well as how they’re being summarized.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="iv-visualization">iv. Visualization<a href="#iv-visualization" class="hash-link" aria-label="Direct link to iv. Visualization" title="Direct link to iv. Visualization">​</a></h4><p>Visualization is concerned with how data is displayed. One way to view load testing data is with an aggregated end-of-test summary. This makes results easy to parse and provides a high-level overview of how the system responded to the simulated load.</p><div class="language-txt codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_Ktv7">wrk summary</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-txt codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Running 30s test @ http://127.0.0.1:8080/index.html</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  12 threads and 400 connections</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Latency   635.91us    0.89ms  12.92ms   93.69%</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Req/Sec    56.20k     8.07k   62.00k    86.54%</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  22464657 requests in 30.00s, 17.76GB read</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Requests/sec: 748868.53</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Transfer/sec:    606.33MB</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>One drawback of this approach is that it lacks granularity. Because data is not plotted against a time axis, there’s not enough detail to identify when exactly problems start to arise and discern any trends.</p><p>Another drawback is that summaries are only generated at the end of a test. For a short test waiting for these results may not be an issue. However, load tests can be very long (sometimes they even take days). Displaying results in an end-of-test summary and forcing the developer to wait through the duration of the test hinders the usability of the load testing tool.</p><p>An alternative to end-of-test summaries is to use a visualization dashboard. These dashboards display data against a time axis, allowing the developers to have a better understanding of the data. For example, the graph below can be used to pinpoint the specific time system performance shifts, which occurs at about the three minute mark.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 2.4: Example of a data visualization dashboard</p></div><p>Moreover, these dashboards often display data in near real-time, allowing developers to react to live results as they occur. Depending on the nature of the load test, developers might either scale up server resources to handle the additional load or stop the test.</p><p>The main drawback with this approach is that near real-time processing is an engineering challenge, and may not be worth the additional complexity involved based on developer needs.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="c-summary">c. Summary<a href="#c-summary" class="hash-link" aria-label="Direct link to c. Summary" title="Direct link to c. Summary">​</a></h3><p>Load testing can involve many considerations. On the most basic level, developers need to consider the required scale of the load test, the protocol(s) being tested, the metrics being considered to evaluate performance, and how data is being visualized.</p><p>An application’s capabilities and complexity can introduce additional factors. For example, messaging applications and collaboration tools have specific characteristics that need to be considered when determining what load testing approach should be taken.</p><p>In the next section, we will take a look at how collaboration apps work and how these pose specific challenges that need to be answered by an effective load testing tool.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-background-real-time-collaboration-apps">3. Background: Real-time collaboration apps<a href="#3-background-real-time-collaboration-apps" class="hash-link" aria-label="Direct link to 3. Background: Real-time collaboration apps" title="Direct link to 3. Background: Real-time collaboration apps">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="a-what-are-real-time-collaboration-apps">a. What are real-time collaboration apps?<a href="#a-what-are-real-time-collaboration-apps" class="hash-link" aria-label="Direct link to a. What are real-time collaboration apps?" title="Direct link to a. What are real-time collaboration apps?">​</a></h3><p>Real time collaboration apps are applications that enable team members to work together, communicate, and collaborate simultaneously over the web. Real time collaboration apps can be categorized into various types based on their features:</p><ul><li><strong>Messaging</strong>: Apps like Slack, Discord, or Mattermost allow users to join rooms or channels and talk to each other in real time.</li><li><strong>Whiteboarding</strong>: Whiteboard apps Miro and Whimsical give teams a visual platform to collaborate on brainstorming aids and graphic deliverables like mind maps or flow charts.</li><li><strong>Productivity</strong>: Coda and similar productivity tools empower teams to perform project management by collaborating on documents, tables, tasks, and more.</li></ul><p>All of these tools benefit from low-latency data transfer (~100ms)<sup id="fnref-6"><a href="#fn-6" class="footnote-ref">6</a></sup> and the ability for a server to push data directly to a client even in the absence of a request. Collaboration apps often rely on WebSockets to help them achieve these goals.</p><p><strong>WebSocket</strong> is a protocol that operates over HTTP and uses the underlying TCP layer to create a persistent connection between client and server.<sup id="fnref-7"><a href="#fn-7" class="footnote-ref">7</a></sup> Unlike HTTP, where the client must initiate communication with the server by first sending a request, WebSockets enables bi-direction communication between client and server. Although a WebSocket connection is initially established via an HTTP request, the protocol is subsequently updated to a persistent connection, allowing the server to stream events back to the client in real time.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 3.1: The difference between an HTTP and Websocket connection</p></div><p>On the client side, a browser relies on a WebSocket object to facilitate this persistent connection. The WebSocket object uses event-based asynchronous callbacks to handle incoming messages from the server, and it can also send messages directly to the server. WebSocket messages, unlike HTTP requests, don&#x27;t require a response.</p><p>On the server side, a program must be running that’s capable of following the WebSocket protocol and listening for messages. This program is responsible for connecting to clients, sending and receiving messages, and managing the persistent connection. While it is possible to handle WebSocket and HTTP connections from the same host, developers often prefer to use dedicated services for each type of connection to improve scalability. This can increase the complexity of the architecture since traffic now exists in two places – the WebSocket server and the HTTP server.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="b-considerations-when-developing-a-collaboration-app">b. Considerations when developing a collaboration app<a href="#b-considerations-when-developing-a-collaboration-app" class="hash-link" aria-label="Direct link to b. Considerations when developing a collaboration app" title="Direct link to b. Considerations when developing a collaboration app">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="i-websocket-performance">i. WebSocket performance<a href="#i-websocket-performance" class="hash-link" aria-label="Direct link to i. WebSocket performance" title="Direct link to i. WebSocket performance">​</a></h4><p>WebSocket and HTTP are two distinct protocols, which means that developers require different metrics to measure their performance. HTTP operates on a request-response cycle, so developers often measure latency-related metrics like HTTP response time. WebSockets, on the other hand, does not require a response after the initial connection has been established. Since WebSocket messages often follow a “fire and forget” pattern, there’s less concern with how a “request” relates to a “response”.</p><p>The persistent connection of WebSockets necessitates additional performance metrics, such as the number of current connections and the number of dropped connections. Since the management of these connections requires server resources (like CPU and memory), unexpected surges in traffic can cause the server to get overloaded. Overloaded WebSocket servers may not be able to initialize new connections, which could result in client-side timeouts or connection failure errors. If resources are fully exhausted, the server might start dropping connections. Dropped connections can lead to degraded user experience, or in some cases even data loss.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="ii-supporting-separate-protocols">ii. Supporting separate protocols<a href="#ii-supporting-separate-protocols" class="hash-link" aria-label="Direct link to ii. Supporting separate protocols" title="Direct link to ii. Supporting separate protocols">​</a></h4><p>Supporting two distinct protocols introduces significant complexity to the system. For example, HTTP and WebSocket servers may have different scaling needs. To determine the scalability thresholds of each, load tests need to be run that address both traffic patterns.</p><p>WebSocket clients exhibit different behavior from those that are connected via HTTP. When an HTTP server fails, traffic can be load balanced and redirected to another server the next time a request is issued (since HTTP servers are often stateless). However, if a WebSocket server fails, all clients are disconnected from that bi-directional communication simultaneously. Often, they all try to reconnect at the same time, which can create a &quot;thundering herd&quot;<sup id="fnref-8"><a href="#fn-8" class="footnote-ref">8</a></sup> problem. Since WebSocket connections are initialized with an HTTP request, this could affect both the HTTP and the WebSocket server. Therefore, applications that support both HTTP and WebSockets need to be able to handle this.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="iii-fan-out-messaging-pattern">iii. Fan-out messaging pattern<a href="#iii-fan-out-messaging-pattern" class="hash-link" aria-label="Direct link to iii. Fan-out messaging pattern" title="Direct link to iii. Fan-out messaging pattern">​</a></h4><p>The fan-out messaging pattern uses a one-to-many arrangement to emit messages, which enables a collaboration app to distribute messages to all users connected to the same channel in real-time. A message could be a chat message, a user&#x27;s mouse movements, entering text into a shared document, drawing something on a whiteboard, or any other sort of data that needs to be propagated back up to collaborators.</p><p>For these types of apps, the message can be published through an HTTP request or WebSocket message from the client. To enable real-time communication, messages are sent back up to subscribed collaborators via WebSockets. Depending on how large the channel is, one published message can lead to a sizable fan-out.</p><p>For example, if a user sends a message to a Slack channel with 1k subscribers, the single POST request that sends the message turns into 1k WebSocket messages being emitted. That’s not necessarily where the fan-out ends, however. If other users start liking or reacting to that message it can compound the problem. Each time a user reacts, it creates a new message which has to be sent back out to all 1k users in the channel.</p><p>This could lead to a large amount of fan-out where the WebSocket server might be required to send out one million messages (1k likes times 1k clients). Since all of this is supposed to be happening in real-time, all of the messages need to be sent out very quickly. This can place a significant burden on the WebSocket server, since it needs to accomplish all this work in a short period of time.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 3.2: Depiction of fanout</p></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="c-summary-1">c. Summary<a href="#c-summary-1" class="hash-link" aria-label="Direct link to c. Summary" title="Direct link to c. Summary">​</a></h3><p>Managing a real-time collaboration app poses a unique set of circumstances that developers must take into consideration. WebSocket servers and clients behave differently than their HTTP counterparts, so additional scenarios like WebSocket performance, thundering herds, and fan-out messaging must be accounted for. To ensure readiness for these scenarios, developers should perform load tests that accurately simulate these behaviors.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-load-testing-for-collaboration-apps">4. Load testing for collaboration apps<a href="#4-load-testing-for-collaboration-apps" class="hash-link" aria-label="Direct link to 4. Load testing for collaboration apps" title="Direct link to 4. Load testing for collaboration apps">​</a></h2><p>The rise of remote work has led to a surge in popularity for real time collaboration apps.
For example, Miro grew from 12k to 100k concurrently connected users in less than one year.<sup id="fnref-9"><a href="#fn-9" class="footnote-ref">9</a></sup> This type of rapid growth requires scalability, which can compound the challenges listed in the previous sections.</p><p>A load testing tool built for these types of applications should have a certain set of characteristics to be effective.</p><ul><li>Load tests need to ensure that all components of the architecture are tested, meaning that virtual users should be able to mimic both HTTP and WebSocket clients.</li><li>Load tests should be capable of generating at least 100K virtual users per test to support the needs of medium-to-large collaboration apps.</li><li>Load tests should be able to collect and display granular data pertaining to both HTTP and WebSockets. To ensure that developers can react to potential issues or stop a test while it is running, this data should be displayed in near real-time.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="a-generating-http-and-websocket-traffic">a. Generating HTTP and WebSocket traffic<a href="#a-generating-http-and-websocket-traffic" class="hash-link" aria-label="Direct link to a. Generating HTTP and WebSocket traffic" title="Direct link to a. Generating HTTP and WebSocket traffic">​</a></h3><p>Typically, the HTTP server and WS server need to be tested in tandem to get an accurate picture of how the system responds to load from real end-users. For applications that only support HTTP endpoints, an HTTP load tester is sufficient. However, collaboration apps cannot rely on HTTP requests alone for load testing, since client traffic is divided between two different protocols. HTTP-focused load tests do not cover all components of a collaboration app’s architecture.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 4.1: A load test using an HTTP API blaster only tests part of the system and doesn’t test any real time services that rely on WebSockets</p></div><p>In an HTTP load test, requests are sent to the HTTP server. In response, this causes data to be sent to the WebSocket server so that published messages can be propagated to subscribed end-users. However, if the virtual users in the load test do not maintain persistent WebSocket connections, the WebSocket server never has to emit any messages (since there are no active subscribers). This means that a critical part of the architecture never has to sustain any load.</p><p>Due to fan-out messaging, the number of WebSocket messages that must be sent (and therefore, the amount of load the WebSocket server must sustain) can be orders of magnitude different from the number of HTTP requests being received. It is important that the virtual users in the load test accurately simulate the persistently connected WebSocket clients.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 4.2: A system can be tested holistically if the load tester has virtual users that can establish persistent Websocket connections</p></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="b-scaling-to-100k-concurrent-users">b. Scaling to 100K+ concurrent users<a href="#b-scaling-to-100k-concurrent-users" class="hash-link" aria-label="Direct link to b. Scaling to 100K+ concurrent users" title="Direct link to b. Scaling to 100K+ concurrent users">​</a></h3><p>Collaboration apps have different needs for load tests, as the number of daily active users varies from company to company. For example, Miro grew from 12k to 100k concurrently connected users in less than a year. <sup id="fnref-9"><a href="#fn-9" class="footnote-ref">9</a></sup> Another large real-time collaboration app we contacted privately indicated they were running load tests of up to 100k concurrent users. For Slack, load tests range from 5k to 500k virtual users.<sup id="fnref-10"><a href="#fn-10" class="footnote-ref">10</a></sup> Based on these numbers, we believe that an effective load tester for medium-to-large collaboration apps should be able to run load tests in the six-figure range (at least 100k virtual users).</p><p>Running load tests with 100K+ virtual users will quickly outstrip the compute resources available on a single machine, and will therefore require a distributed architecture. While it’s possible to run distributed load tests using on-premises servers, developers will often run load tests on servers hosted by cloud providers like AWS. This provides greater flexibility and scalability, allowing developers to quickly provision and deprovision resources as needed for testing without additional hardware investments. That being said, distributed cloud-based load testing adds additional complexity and requires both management and coordination of cloud infrastructure.</p><p>One of the major concerns with distributed load testing involves the synchronization of load generators running on separate hosts. Load tests often have a predefined pattern for ramping the number of virtual users up and down. Different patterns test how systems respond to different scenarios.</p><p>In the example below, both load generators are ramping up to a peak load of 10k virtual users, and since the tests are synchronized they will reach a combined peak of 20k virtual users for the load test.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 4.3: A synchronized load test</p></div><p>However, if one of the load generators is out of sync, the overall test will never hit the peak load of 20k virtual users.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 4.4: An unsynchronized load test</p></div><p>This is a major issue, especially if developers are trying to test for a specific load that never gets simulated. Therefore, an effective load testing tool needs a way to synchronize load generator nodes to ensure they all start ramping up the load at the same time. Without such a synchronization mechanism, there is no way to guarantee the load test is simulating the predefined pattern of user load.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="c-collecting-and-displaying-data-in-near-real-time">c. Collecting and displaying data in near real-time<a href="#c-collecting-and-displaying-data-in-near-real-time" class="hash-link" aria-label="Direct link to c. Collecting and displaying data in near real-time" title="Direct link to c. Collecting and displaying data in near real-time">​</a></h3><p>Finally, an effective load testing tool for real-time collaboration apps should be able to display data in near real-time. This enables developers to run load tests against a variety of environments.</p><p>Often, staging environments are used to mirror production environments. This provides a level of isolation that enables load tests to be conducted without fear of taking down any critical production services. That being said, developers may still want to run tests against production for a number of reasons:</p><ul><li>Running load tests against production often yields the most accurate results.<sup id="fnref-11"><a href="#fn-11" class="footnote-ref">11</a></sup></li><li>Some companies may not have the time or financial resources to implement a full duplicated staging environment.</li><li>There may be overlapping resources between staging and production, in which case running a load test against staging could still affect critical production components.</li></ul><p>Running load tests against production comes with a variety of risks. The additional load might cause performance of the application to degrade for real end-users. For example, the application could become unresponsive, unreliable, or even crash. In the worst case scenario, running load tests against production can put stress on the underlying database, resulting in data loss or corruption.</p><p>A near real-time load-testing dashboard allows developers to monitor load test results to ensure that they’re not degrading end-user experience on their production application, and allows them to stop the test entirely if the production server starts to get overwhelmed.</p><p>To facilitate this near real-time visualization of data, the load testing tool should perform stream processing rather than batch processing. Batch processing presupposes the data has a defined start and finish, meaning that batch processing delivers results like end-of-test summaries.<sup id="fnref-12"><a href="#fn-12" class="footnote-ref">12</a></sup> This does not allow developers to act upon results while the load test is running.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 4.5: To facilitate near time visualization, load testers require stream processing instead of batch processing.</p></div><p>Stream processing, on the other hand, assumes data is unbound and arrives continually over time.<sup id="fnref-12"><a href="#fn-12" class="footnote-ref">12</a></sup> To derive analytics like percentiles from a data stream, the system splits data up into time intervals. All the data points that fit into one of these “windows” are aggregated and sent to storage. This comes with challenges of its own.</p><p>The amount of data depends on a variety of factors, including the type of load test, which load testing tool is used to conduct the test, which metrics are being collected, and how frequently they are being collected. For example, a test in which virtual users are making HTTP requests each second would result in a higher amount of data than a test in which a request is made every ten seconds.</p><p>If load tests are very large, the amount of data output could overwhelm the resources available in the stream processing pipeline. In this case, the stream processing pipeline needs to vertically or horizontally scale to deal with the amount of data, without diminishing accuracy or reliability of that data.</p><p>Finally, a load testing tool needs a storage method and an effective visualization tool that can display all this data in an understandable way. The visualization tool can then continually pull from the storage as data flows into the system, allowing developers to see data in near-real time as they execute the test.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-existing-solutions">5. Existing solutions<a href="#5-existing-solutions" class="hash-link" aria-label="Direct link to 5. Existing solutions" title="Direct link to 5. Existing solutions">​</a></h2><p>There are many existing solutions for load testing tools like k6, Locust, JMeter, and Artillery. While all these companies offer open-source load testers, they are typically meant for local use, meaning resources for producing high numbers of virtual users are limited to one host. However, our specifications require supporting at least 100k users per test, which necessitates a distributed architecture composed of multiple hosts.</p><p>It is possible to use an open-source tool in a distributed manner, but it involves managing all the necessary cloud infrastructure yourself. For example, in this approach developers running the test would be responsible for setting up the infrastructure to run a distributed test, collecting streaming data from multiple sources, storing all the data in a database, and setting up visualization tools to display the data. Some tools, like JMeter, offer guides<sup id="fnref-13"><a href="#fn-13" class="footnote-ref">13</a></sup> and a controller construct to help users run distributed tests. If a company has very specific needs, it may consider developing a self-hosted DIY tool rather than extending the capabilities of an open-source tool by distributing the test.</p><p>This approach, however, involves significant complexity. Many open-source load testing tools offer managed cloud-based services that abstract away all the challenges of distribution. While this is a convenient option, it does come with limitations such as lack of data ownership and high cost.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 5.1: Edamame falls in the middle of the two levels of abstraction.</p></div><p>Edamame is one of a few solutions that belong between the two different levels of abstraction of self-hosted DIY tools and managed cloud-based services. It provides a load testing tool with built-in distribution management that&#x27;s simple to deploy and run.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="a-diy">a. DIY<a href="#a-diy" class="hash-link" aria-label="Direct link to a. DIY" title="Direct link to a. DIY">​</a></h3><p>Several real-world collaborative apps have taken a DIY approach to either develop a custom load testing tool or extend an existing open-source tool and manage the distribution.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 5.1: Slack&#x27;s DIY tool for load testing called “Koi Pond”</p></div><p>Slack built Koi Pond<sup id="fnref-10"><a href="#fn-10" class="footnote-ref">10</a></sup>, which is an internal tool that leverages a distributed Kubernetes architecture to ensure sufficient connected virtual users. Load is generated using a custom tool written in Go, and virtual user behavior is dictated by a JSON file. Koi Pond streams data which is displayed in a Grafana dashboard as a test runs.</p><p>Miro facilitates WebSocket load testing by extending JMeter with a plugin and custom scripts. To mitigate the costs associated with running load tests on AWS, they use temporary Spot instances which are only active for the duration of the test.<sup id="fnref-9"><a href="#fn-9" class="footnote-ref">9</a></sup></p><p>Neither of these two tools, however, are available for public use. They represent proprietary technology that’s only available at the company that specifically developed them.</p><p>For developers looking to build their own framework for running distributed load tests, AWS<sup id="fnref-14"><a href="#fn-14" class="footnote-ref">14</a></sup> and Google Cloud<sup id="fnref-15"><a href="#fn-15" class="footnote-ref">15</a></sup> both have guides on how to manage the underlying infrastructure to facilitate this. In this approach, the developer takes on all responsibility for the challenges associated with running a distributed test.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="b-managed-cloud-based-services">b. Managed cloud-based services<a href="#b-managed-cloud-based-services" class="hash-link" aria-label="Direct link to b. Managed cloud-based services" title="Direct link to b. Managed cloud-based services">​</a></h3><p>If a developer does not wish to manage the complexity involved with a distributed load test, using a cloud-based solution abstracts away many of the challenges involved. Cloud-based solutions are paid services that handle all underlying infrastructure for running tests, data collection, data processing, near real-time visualization, and data storage. This makes it very easy for developers to run large-scale load tests.</p><p>That being said, cloud-based solutions also have their trade-offs. They can be very costly.<sup id="fnref-16"><a href="#fn-16" class="footnote-ref">16</a></sup> Moreover, because all data storage is managed, users do not retain control over their own data. Different cloud-based solutions will place different limits on how long data is retained.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 5.3: A comparison of cloud-based solutions</p></div><p><sup id="fnref-16"><a href="#fn-16" class="footnote-ref">16</a></sup></p><p>Another issue is that cloud-based solutions are not very flexible. For example, the k6 open-source load tester is quite extensible, which allows developers to customize which metrics their load tests are tracking by default. However, the k6 cloud platform does not support utilizing these extensions,<sup id="fnref-17"><a href="#fn-17" class="footnote-ref">17</a></sup> which compromises developer experience.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="c-an-in-between">c. An in-between<a href="#c-an-in-between" class="hash-link" aria-label="Direct link to c. An in-between" title="Direct link to c. An in-between">​</a></h3><p>Developers can also use a self-hosted tool to run distributed load tests. These enable users to run distributed tests on their own infrastructure, and are typically either open source or licensed software. This approach is less abstracted than managed cloud-based services, but more abstracted than a proprietary DIY tool.</p><p>Artillery is one example of an open-source tool that allows for distributed load tests that are easy to deploy;<sup id="fnref-18"><a href="#fn-18" class="footnote-ref">18</a></sup> however, it comes with significant drawbacks. Tests are run on the user’s AWS account using AWS Lambda (AWS&#x27;s serverless function offering), which limits them to a 15-minute duration. Distributed load tests run using Artillery also cannot be stopped mid-test.</p><p>Gatling Enterprise’s licensed tool is another example of a self-hosted solution. In this case, developers can pay a licensing fee to use Gatling’s software on their own infrastructure. The software takes care of running distributed load tests, but not the management of the underlying architecture, data storage, or other external considerations.</p><p>Edamame lives in the liminal space between a DIY and a SaaS solution. It’s open-source and provides many of the benefits of a cloud-based service such as managed distribution and near real-time data visualization. It also addresses the primary limitation of these services by giving users full control over their data. Edamame is built with collaboration apps in mind and features meaningful metrics for both HTTP and WebSockets out of the box.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 5.4: Comparing Edamame with open-source and cloud-based load testing tools</p></div><p>Edamame is a specific tool built for a specific use case, so it has limitations as well. Applications that need to support high levels of concurrency may not wish to utilize Edamame, as it does not support more than 200k virtual users per test. Edamame does not integrate into a CI/CD pipeline like GitHub Actions or Jenkins. Because Edamame targets collaborative apps, it does not support protocols outside HTTP and WebSockets.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-edamame-architecture">6. Edamame architecture<a href="#6-edamame-architecture" class="hash-link" aria-label="Direct link to 6. Edamame architecture" title="Direct link to 6. Edamame architecture">​</a></h2><p>Edamame has three major components:</p><ol><li>The <strong>Load Generation</strong> component is responsible for simulating virtual users across multiple hosts. This consists of two entities: the runners generate HTTP and WebSocket traffic which creates artificial load on the target system and the coordinator ensures that the runners are synchronized.</li><li>The <strong>Data Handling</strong> component is responsible for receiving, processing, and storing the data emitted by the load generation component.</li><li>The <strong>Data Visualization</strong> component provides a custom dashboard that allows for meaningful analysis of test results in near real-time.</li></ol><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 6.1: Edamame architecture</p></div><p>Edamame runs on Amazon Web Services, or AWS. Before the user can run any tests, all the necessary infrastructure is deployed to their AWS account.</p><p>To run a test with Edamame, the user must provide a test script. Edamame evaluates this test script, and scales up the resources needed for the runners and the data pipeline. When this is ready, a signal is sent to the coordinator, which enables the runners to execute the given test script in a synchronized manner. Client-side data output by the runners gets sent to the data pipeline, where it gets processed, and then sent to the database for storage. Finally, the visualizer grabs the data from the database, which gives the user access to a dashboard that they can use to see live results.</p><p>Once the test is complete, test runner and data pipeline components are scaled back down, and Edamame goes back to its initial “resting state”.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="7-building-edamame-load-generation">7. Building Edamame: Load Generation<a href="#7-building-edamame-load-generation" class="hash-link" aria-label="Direct link to 7. Building Edamame: Load Generation" title="Direct link to 7. Building Edamame: Load Generation">​</a></h2><p>We’ll start off by talking about the “Load Generation” component of our architecture, which involves generating load and coordinating distributed load tests.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 7.1:  Load generation component of the Edamame architecture</p></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="a-scaling-to-100k-virtual-users">a. Scaling to 100k+ virtual users<a href="#a-scaling-to-100k-virtual-users" class="hash-link" aria-label="Direct link to a. Scaling to 100k+ virtual users" title="Direct link to a. Scaling to 100k+ virtual users">​</a></h3><p>Since the target developers for Edamame require the ability to run load tests of at least 100k concurrent virtual users, a distributed architecture is required. Distributed load tests require multiple hosts to have a load testing tool installed. However, manually installing and configuring that tool on a potentially large number of hosts is inefficient, error prone, and difficult to maintain.</p><p>To get around this, developers can use containers, which duplicate applications along with their environment and dependencies for efficient deployment to multiple hosts. Therefore, Edamame leverages containers to distribute multiple instances of the selected load testing tool. These containers run on Amazon’s EC2 instances in the user’s AWS account.</p><p>The question then became; which load testing tool should Edamame utilize for its distributed tests? There are many open source load testing tools available that fit our use case to varying degrees. We looked at two main considerations:</p><ul><li>The load testing tool should be able to generate traffic for both HTTP and WebSockets in order to mimic the users of a collaboration app.</li><li>The load testing tool should be performant, meaning it should require minimal resources to generate the desired amount of load, enabling an efficient use of distributed hosts.</li></ul><p>In terms of performance, because Edamame needs to support more than 100k virtual users, we required a load testing tool that had efficient use of both CPU and RAM.</p><ul><li>CPU efficiency corresponds to Requests Per Second (RPS). A high RPS means less CPU is utilized per request, so requests can be sent at a faster rate.</li><li>RAM usage is determined by how much memory is required per virtual user. The less memory consumed per VU, the greater the number of VUs that can be supported by a single host.</li></ul><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 7.2: Comparison of open-source load testing tools</p></div><p><sup id="fnref-4"><a href="#fn-4" class="footnote-ref">4</a></sup></p><p>Ultimately, we chose k6 because it efficiently uses compute resources relative to other load testing tools. It is very lightweight in terms of RAM usage per VU and has a high RPS. Furthermore, it enables developers to write virtual user behaviors using JavaScript, a well-known language, and supports both HTTP and WebSockets. Finally, k6 is highly extensible, which means we were able to customize it in a number of ways. This gave us a lot of flexibility when it came to deciding the rest of the components in our architecture.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="b-synchronizing-load-generators">b. Synchronizing load generators<a href="#b-synchronizing-load-generators" class="hash-link" aria-label="Direct link to b. Synchronizing load generators" title="Direct link to b. Synchronizing load generators">​</a></h3><p>Containers gave us a way to efficiently deploy multiple instances of k6 to cloud servers for running distributed load tests. This meant we could deploy as many instances of k6 as necessary to reach the desired number of virtual users. However, these containers were isolated and unaware of each other. As previously mentioned, distributed load generators must be synchronized to ensure accurate results.</p><p>Containers are meant to be stateless. This is an issue, since synchronizing load generators requires managing the container state. This is because the status of all load generator containers must be known before the test can begin execution.</p><p>One approach to solve the problem of test synchronization is to use a leader-follower model for load generators. This means that a single container (the “leader”) would be responsible for determining test parameters and sharing those parameters with a number of “follower” containers. Follower containers would not begin test execution until they receive a command from the leader.<sup id="fnref-19"><a href="#fn-19" class="footnote-ref">19</a></sup></p><p>However, configuring the leader-follower model for k6 load generators would require a number of custom components. First, the leader would need to be aware of all the IPs of the followers to communicate with them. This would also require some mechanism for monitoring readiness of each load generator. Finally, it would necessitate additional functionality for the leader to send a simultaneous start signal to all followers. The complexity involved with developing all these custom components led us to look for a simpler option.</p><p>K6 provides a means to synchronize tests in the form of the k6 operator, which can be deployed with Kubernetes. Kubernetes is a container orchestration tool that provides a layer of abstraction over containers and allows communication between different containers across various hosts and environments.<sup id="fnref-20"><a href="#fn-20" class="footnote-ref">20</a></sup></p><p>To achieve this, Kubernetes gives us a number of components, such as Operators. Operators are meant to mimic the behavior of a human operator that manages a service.<sup id="fnref-21"><a href="#fn-21" class="footnote-ref">21</a></sup> For example, it handles installing specific applications and ensuring that those applications are healthy within different containers. Therefore, they help us solve this problem of container state management.</p><p>To leverage the k6 operator for synchronizing load tests, Edamame deploys its infrastructure on AWS’s Elastic Kubernetes Service (EKS). This means that containerized applications (like k6) will be deployed on hosts in an EKS cluster.</p><p>When a user runs a load test with Edamame, they provide a test script which defines a quantity of virtual users and their behavior. This test script is applied to the EKS cluster as a configuration value that Kubernetes makes available to any containers running within the cluster. The k6 operator accesses the test script and manages the execution of the test.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 7.3:  The K6 operator simplifies the process of synchronizing load tests</p></div><ol><li>First, the operator creates a new component called the initializer. This is a program that performs error handling (e.g. it checks the validity of the test script).</li><li>Next, the operator creates test runners. These encapsulate the k6 load testing application and are responsible for accessing the test script, generating the load, and running the test.</li><li>Third, the operator creates a starter program that is responsible for starting the execution of the test simultaneously in all test runners.</li><li>Finally, after creating these three components, the k6 operator continuously polls the test runners for readiness, and when they are all ready, sends a signal to the starter to start the test execution.<sup id="fnref-22"><a href="#fn-22" class="footnote-ref">22</a></sup></li></ol><p>The k6 operator allowed us to synchronize our k6 instances running on different hosts, but one problem remained - Edamame still needed to specify the number of k6 runners that would be required for each test. This value is determined by the optimal number of VUs per runner, so the challenge became finding a number that both maximized runner CPU and memory without overloading these resources.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="c-optimizing-compute-resources">c. Optimizing compute resources<a href="#c-optimizing-compute-resources" class="hash-link" aria-label="Direct link to c. Optimizing compute resources" title="Direct link to c. Optimizing compute resources">​</a></h3><p>The number of runners required for each test is specified by Edamame using a value known as <strong>parallelism</strong>. This determines how many virtual users are being generated by each runner.<sup id="fnref-22"><a href="#fn-22" class="footnote-ref">22</a></sup> For example, if a test script specifies a peak of 200 virtual users and parallelism is set to two, this will create two runners, each of which is responsible for generating 100 virtual users. On the other hand, a test script that specifies 200k virtual users with parallelism set to two will create two runners responsible for generating 100k virtual users each.</p><p>When a test runner is “overloaded” with too many virtual users, a number of issues might occur:</p><ul><li>The runner might not have enough CPU or RAM to produce the correct number of virtual users. If this is the case, developers might see the number of VUs in the test plateau and never reach the peak load specified in the test script.</li><li>There might not be enough available bandwidth to handle all the requests being sent. If that’s the case, the number of requests sent will not match what is specified in the test script.</li></ul><p>One way to deal with overloading is to play it safe, by setting an artificially low number of virtual users for each runner. However, this results in provisioning more compute resources for test runners than is actually required, which is inefficient. Therefore, the best way to ensure Edamame does not overload the test runners is to find the optimal number of VUs per runner and calculate parallelism dynamically based on that number.</p><p>K6 benchmarks<sup id="fnref-23"><a href="#fn-23" class="footnote-ref">23</a></sup> indicate that up to 60k virtual users can be supported by a single <code>m5.24xlarge</code> host that has kernel level configurations applied to increase maximum requests per second. That being said, how test scripts are written can radically affect how much memory a single virtual user requires. The official k6 recommendation<sup id="fnref-24"><a href="#fn-24" class="footnote-ref">24</a></sup> is to run no more than 30-40k virtual users per host.</p><p>Edamame sets a default value of 20k virtual users per runner, but provides the option to change this value. This allows developers to set the number of virtual users per runner that best suits the specific needs of their test scripts.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="8-building-edamame-data-handling">8. Building Edamame: Data Handling<a href="#8-building-edamame-data-handling" class="hash-link" aria-label="Direct link to 8. Building Edamame: Data Handling" title="Direct link to 8. Building Edamame: Data Handling">​</a></h2><p>Next, we’ll talk about the “data handling” component of our architecture, which involves stream processing 1M+ data points per second.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 8.1: Data handling component of the Edamame architecture</p></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="a-processing-1m-data-points-per-second">a. Processing 1M data points per second<a href="#a-processing-1m-data-points-per-second" class="hash-link" aria-label="Direct link to a. Processing 1M data points per second" title="Direct link to a. Processing 1M data points per second">​</a></h3><p>While k6 met most of our requirements for a load testing tool, it does have a significant trade-off: it generates a huge amount of data. By default, k6 will output all the raw data from the load test without any kind of aggregation. For example, a test that simulates 100k virtual users — where each VU sends a WebSocket ping every second or an HTTP request every six seconds — results in an output of about 1 million data points per second.</p><table><thead><tr><th>VUs</th><th>data points/sec</th></tr></thead><tbody><tr><td>1K</td><td>~10K</td></tr><tr><td>10K</td><td>~100K</td></tr><tr><td>100K</td><td>~ 1 M</td></tr></tbody></table><p>We explored three ways to process all this data in near real-time:</p><ul><li>Write the raw data to a database</li><li>Aggregate on the load generators before outputting to reduce data</li><li>Aggregate data centrally in a stream processing pipeline</li></ul><p>The first approach was to write data directly to a performant database. Since load testing data is typically plotted along a time axis, a time series database would have been appropriate for this use case.</p><p>Initially, we tried writing data to InfluxDB, a time series database optimized for write-heavy applications. However, we found that InfluxDB was overwriting data points, which led to inaccurate results. If two data points contain the same metric name, tag set, and timestamp InfluxDB considers them to be the same. Therefore data points received later can overwrite previously stored values that have the same characteristics.</p><p>We also tried sending data directly to TimescaleDB and found it could only handle about 100k writes per second. To avoid highly complex components such as a sharded or distributed database,<sup id="fnref-25"><a href="#fn-25" class="footnote-ref">25</a></sup> we decided to try a different approach and attempt to aggregate data before storing it in the database.</p><p>The second option was to aggregate on each load generator. This would involve writing a k6 extension to aggregate raw test data before outputting it from the runners. Ideally, this preprocessing would result in a more manageable amount of data. However, there is an issue with this approach stemming from the fact that each load generator represents only a subset of the data.</p><p>We cannot aggregate metrics that we want to summarize with percentiles, such as HTTP response time, at each load generator. Doing so would potentially compromise the accuracy of the percentiles.</p><p>If we take the response times from each runner, find the 99th percentile, and then average them across runners, we’re not guaranteed to get the correct value, especially if a specific runner is for some reason receiving much faster or slower response times.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 8.2: The problem with aggregating percentile metrics across machines</p></div><p>To ensure the aggregated percentile value is correct, it needs to be calculated with the entire data set. Based on these considerations, we ultimately decided to use a centralized stream processing server to aggregate load testing data in a single location. This would ingest data output by the test runners and output aggregated data points to the database on predetermined time windows known as “flush intervals”.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="b-stream-processing-pipeline">b. Stream processing pipeline<a href="#b-stream-processing-pipeline" class="hash-link" aria-label="Direct link to b. Stream processing pipeline" title="Direct link to b. Stream processing pipeline">​</a></h3><p>To implement this approach and process data centrally, we still needed to find a server that could handle the 1M data points per second output by the test runners.</p><p>StatsD is a server and protocol developed by Etsy for large-scale centralized data aggregation.<sup id="fnref-26"><a href="#fn-26" class="footnote-ref">26</a></sup> The StatsD protocol is lightweight and text based. The StatsD server, however, has limitations. It was written in NodeJS, and lacked some of the efficiency we required. Namely, it only handles an ingestion rate of 10k data points/sec.<sup id="fnref-27"><a href="#fn-27" class="footnote-ref">27</a></sup> There is, however, another implementation of the StatsD server called Statsite, written in C.</p><p>Statsite uses a single core with an event loop to handle much more data than the original StatsD server. It&#x27;s also highly efficient when it comes to data aggregation. Trend based data points (e.g. HTTP response time) are aggregated into the specified percentiles using the count-min sketch,<sup id="fnref-28"><a href="#fn-28" class="footnote-ref">28</a></sup> a probabilistic data structure that is much faster than sorting all of the raw data to arrive at the needed percentile. Probabilistic data structures like this allow us to &quot;calculate a good approximation of percentiles at minimal CPU and memory cost&quot; (Kleppman).<sup id="fnref-29"><a href="#fn-29" class="footnote-ref">29</a></sup></p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 8.3: Stream processing using a Statsite server (built on the StatsD protocol)</p></div><p>Overall, using Statsite allows Edamame to significantly minimize the number of database writes per second. For example, if the load test tracks 20 metrics, the result is 20 writes per five-second flush interval.</p><p>Since the data aggregation pipeline was able to minimize the number of writes per second so significantly, we no longer needed a specialized database for data storage. Therefore, Edamame utilizes PostgreSQL for data storage. This makes it easy for the user to set up any custom dashboards or queries necessary to visualize data, since PostgreSQL utilizes the well-known query language SQL.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="9-building-edamame-data-visualization">9. Building Edamame: Data Visualization<a href="#9-building-edamame-data-visualization" class="hash-link" aria-label="Direct link to 9. Building Edamame: Data Visualization" title="Direct link to 9. Building Edamame: Data Visualization">​</a></h2><p>Finally, we’ll talk about the “data visualization” component of our architecture, which involves visualizing important data for both HTTP and WebSockets.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 9.1: Data visualization component of the Edamame architecture</p></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="a-extracting-meaningful-insights">a. Extracting meaningful insights<a href="#a-extracting-meaningful-insights" class="hash-link" aria-label="Direct link to a. Extracting meaningful insights" title="Direct link to a. Extracting meaningful insights">​</a></h3><p>While data was being successfully processed and stored, we still needed to give developers a way to make sense of that data. Grafana, a data visualization tool, provides a solution for this problem. Plotting metrics against the time they were collected allows users to pinpoint shifts in their system’s performance.</p><p>Edamame uses Grafana because it is open source, easy to use, and highly flexible. For example, users can configure custom dashboards with SQL that track and highlight the metrics most specific to their use case.</p><div class="text--center"><img loading="lazy" src="https://user-images.githubusercontent.com/76174119/228081016-e669dc4d-d1ce-4483-8924-b72ab8c3d1cb.png" alt="Example banner" width="700" class="img_ev3q"><p>Figure 9.2: Grafana HTTP dashboard</p></div><p>After setting up Grafana for data visualization, it became clear that k6 was missing a number of metrics that would have been useful in measuring the performance of a WebSocket server.</p><p>For example, default k6 metrics do not include the current number of WebSocket connections. If the number of virtual users in the test increases while the number of current WebSocket connections starts to plateau, this might indicate that the target system can no longer support additional connections. Another omission is the fact that k6 does not track WebSocket errors by default. An increase in errors could indicate performance issues that might not otherwise be visible.</p><p>K6 provides an interface that allows users to emit custom metrics. However, this requires developers to manually initialize and track each custom metric within their test script. This can become tedious and error prone. For example, to find the number of WebSocket errors, users must wrap code pertaining to custom metrics in a <code>try…catch</code> statement.</p><p>Furthermore, instead of looking at the number of WebSocket errors in general, developers might want to take a more granular look at what’s happening when errors occur. This can be achieved by tracking errors separately. For example, looking at the count of WebSocket abnormal closures can indicate when the server is dropping connections, but looking at the count of WebSocket failed handshakes can indicate when the server is having trouble making new connections. Tracking errors separately in a test script means nested conditionals within <code>try…catch</code> statements, which can make code hard to read and difficult to maintain.</p><div class="language-javascript codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_Ktv7">Test script that tracks WebSocket errors</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-javascript codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword module" style="color:#00009f">import</span><span class="token plain"> </span><span class="token imports punctuation" style="color:#393A34">{</span><span class="token imports"> </span><span class="token imports maybe-class-name">Counter</span><span class="token imports"> </span><span class="token imports punctuation" style="color:#393A34">}</span><span class="token plain"> </span><span class="token keyword module" style="color:#00009f">from</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;k6/metrics&quot;</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword module" style="color:#00009f">import</span><span class="token plain"> </span><span class="token imports punctuation" style="color:#393A34">{</span><span class="token imports"> setInterval </span><span class="token imports punctuation" style="color:#393A34">}</span><span class="token plain"> </span><span class="token keyword module" style="color:#00009f">from</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;k6/x/timers&quot;</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">// ... define duration + # of VUs here ...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> failedHandshakes </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">new</span><span class="token plain"> </span><span class="token class-name">Counter</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;failed_handshakes&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> abnormalClosures </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">new</span><span class="token plain"> </span><span class="token class-name">Counter</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;abnormal_closures&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword module" style="color:#00009f">export</span><span class="token plain"> </span><span class="token keyword module" style="color:#00009f">default</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">function</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">const</span><span class="token plain"> url </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;ws://127.0.0.1:8000/&quot;</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">let</span><span class="token plain"> ws </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">new</span><span class="token plain"> </span><span class="token class-name">WebSocket</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">url</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword control-flow" style="color:#00009f">try</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ws</span><span class="token punctuation" style="color:#393A34">.</span><span class="token method function property-access" style="color:#d73a49">addEventListener</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;open&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token arrow operator" style="color:#393A34">=&gt;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token function" style="color:#d73a49">setInterval</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token arrow operator" style="color:#393A34">=&gt;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ws</span><span class="token punctuation" style="color:#393A34">.</span><span class="token method function property-access" style="color:#d73a49">ping</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10000</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> </span><span class="token keyword control-flow" style="color:#00009f">catch</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">e</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword control-flow" style="color:#00009f">if</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">e</span><span class="token punctuation" style="color:#393A34">.</span><span class="token property-access">message</span><span class="token punctuation" style="color:#393A34">.</span><span class="token method function property-access" style="color:#d73a49">match</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;bad handshake&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      failedHandshakes</span><span class="token punctuation" style="color:#393A34">.</span><span class="token method function property-access" style="color:#d73a49">add</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> </span><span class="token keyword control-flow" style="color:#00009f">else</span><span class="token plain"> </span><span class="token keyword control-flow" style="color:#00009f">if</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">e</span><span class="token punctuation" style="color:#393A34">.</span><span class="token property-access">message</span><span class="token punctuation" style="color:#393A34">.</span><span class="token method function property-access" style="color:#d73a49">match</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;1006&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      abnormalClosures</span><span class="token punctuation" style="color:#393A34">.</span><span class="token method function property-access" style="color:#d73a49">add</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic">// ... can extend if statement to track additional errors...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Instead of asking users to write these custom metrics into their test script, the k6 binary itself can be extended to emit additional metrics by default. On the one hand, this approach increases the complexity of the load generator deployment process by introducing more container dependencies. On the other hand, it has the benefit of automatically extracting meaningful insights into WebSocket performance</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="b-building-a-custom-k6-extension">b. Building a custom k6 extension<a href="#b-building-a-custom-k6-extension" class="hash-link" aria-label="Direct link to b. Building a custom k6 extension" title="Direct link to b. Building a custom k6 extension">​</a></h3><p>We chose to write a custom extension that provides additional useful metrics out of the box. This ensures that users don’t have to worry about repeating verbose code in each of their test scripts to extract insights into WebSocket performance. Moreover, since Edamame is built for a specific use case, highlighting metrics pertinent to that use case make it a more powerful tool.</p><p>To produce better visibility into WebSocket performance, Edamame built a custom k6 extension in Go that tracks five additional metrics.</p><table><thead><tr><th>Metric</th><th>Description</th></tr></thead><tbody><tr><td><code>ws_current_connections</code></td><td>The current number of active WebSocket connections. This is important because the k6 default metrics only provide the total number of connections, rather than how many connections are being persisted at any given time.</td></tr><tr><td><code>ws_failed_handshakes</code></td><td>The number of WebSocket connections that could not be established. An increase in these failures could indicate performance issues with the target system.</td></tr><tr><td><code>ws_abnormal_closure_error</code></td><td>The number of connections that are dropped, measured by counting the number of 1006 abnormal closure error messages.</td></tr><tr><td><code>ws_msgs_bytes_sent</code></td><td>The total number of bytes sent in WebSocket messages. As the size of messages can vary widely, this provides additional context to the default k6 <code>ws_msgs_sent</code> metric.</td></tr><tr><td><code>ws_msgs_bytes_received</code></td><td>The total number of bytes received in WebSocket messages.</td></tr></tbody></table><p>K6 provides two separate WebSocket modules that can be extended. The first, which is part of the k6 core offering, utilizes code syntax that is specific to k6. That is, it does not mirror the more well-known WebSocket API built into modern browsers. This means that in order to use it, developers must familiarize themselves with conventions unique to k6.</p><p>To allow users to write test scripts that more closely mirror the client-side code they may be used to, Edamame forked and extended the second WebSocket module that k6 offers. This is their experimental WebSockets library, which implements the WebSocket API living standard<sup id="fnref-30"><a href="#fn-30" class="footnote-ref">30</a></sup>. This makes writing test scripts more intuitive for users.</p><p>Edamame’s custom k6 extension is packaged into the k6 binary that runs on the load generators. The custom metrics are then emitted into the data pipeline, and written to the database. This enables Edamame to visualize how WebSocket and HTTP servers are performing under heavy load in tandem.</p><div class="text--center"><img loading="lazy" src="/assets/images/logo-light-green-63d3612d3b6478f963f4f702cf93876b.png" alt="Example banner" width="400" class="img_ev3q"><p>Figure 9.3: Edamame’s custom K6 extension</p></div><p>Edamame configures a default custom-dashboard for users that features these additional metrics. The dashboard is specifically designed to show WebSocket metrics in conjunction with HTTP. Since Grafana dashboards are defined using SQL queries, the user can easily customize the default dashboard or create dashboards of their own.</p><div class="text--center"><img loading="lazy" src="https://user-images.githubusercontent.com/76174119/228081027-62238425-b004-482c-b3c7-a11c97411b50.png" alt="Example banner" width="700" class="img_ev3q"></div><div class="text--center"><img loading="lazy" src="https://user-images.githubusercontent.com/76174119/228081016-e669dc4d-d1ce-4483-8924-b72ab8c3d1cb.png" alt="Example banner" width="700" class="img_ev3q"></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="10-future-plans">10. Future plans<a href="#10-future-plans" class="hash-link" aria-label="Direct link to 10. Future plans" title="Direct link to 10. Future plans">​</a></h2><p>Edamame provides a robust framework for performing distributed load tests that target both HTTP and WebSockets. It supports tests of up to 200k virtual users, sufficiently tests complex systems with multiple protocols, and uses a performant data pipeline to aggregate and visualize data in near real-time. That being said, there are several improvements and additional features that could be added in the future.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="a-improving-scalability">a. Improving scalability<a href="#a-improving-scalability" class="hash-link" aria-label="Direct link to a. Improving scalability" title="Direct link to a. Improving scalability">​</a></h3><p>Edamame&#x27;s data pipeline relies on a single instance of a Statsite server to accurately aggregate test metrics into percentiles. Complications in aggregating percentiles limit the ability to scale this component horizontally. Currently, our stream processing relies on a probabilistic data structure that cannot be re-aggregated without losing data integrity. This means that data must be collected in a single location and we cannot currently scale beyond its maximum ingestion rate of 2 million data points per second, or approximately 200k virtual users. This is the main limiting factor when it comes to how many virtual users Edamame can support.</p><p>To simulate more than 200k virtual users without changing Edamame’s current architecture, changes would need to be made to the k6 StatsD output extension, which enables the load generators to output data using the StatsD protocol. Currently, it does not consolidate metrics like counters, which can be easily aggregated without data loss. Summing these data points into a single piece of data would decrease the amount of data being output per virtual user. This increases the amount of simulated load Edamame can generate before reaching Statsite&#x27;s maximum ingestion rate.</p><div class="language-txt codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_Ktv7">Example StatsD output with and without aggregation</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-txt codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># current</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">k6.ws_failed_handshakes:1|c</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">k6.ws_abnormal_closure_error:1|c</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">k6.ws_failed_handshakes:1|c</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">k6.ws_failed_handshakes:1|c</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># consolidated</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">k6.ws_abnormal_closure_error:1|c</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">k6.ws_failed_handshakes:3|c</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Alternatively, we can make the data pipeline more horizontally scalable. This would involve re-working the architecture, by switching to an approach where data is aggregated at each load generator. Special-purpose data structures like <strong>t-digest</strong> <sup id="fnref-31"><a href="#fn-31" class="footnote-ref">31</a></sup> enable percentiles to be aggregated in separate locations. The ability to accurately re-aggregate allows us to perform pre-processing on the load generators. This would immediately cut down on the amount of data being sent through the stream processor, allowing Edamame to scale to even higher numbers of virtual users.</p><p>That being said, aggregating data at each load generator involves sharing compute resources between test runners and data aggregation processes running on the same host. Moreover, there is no current support for t-digest in the k6 ecosystem, nor is there an available t-digest aggregation server, so this approach would involve developing several custom components from scratch.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="b-increased-observability">b. Increased observability<a href="#b-increased-observability" class="hash-link" aria-label="Direct link to b. Increased observability" title="Direct link to b. Increased observability">​</a></h3><p>Edamame specifies a default of 20k virtual users per load generator, but also provides the ability to set a custom number for this value. This leads to the following question: how does the user understand whether or not they are overloading load generator hosts? To provide users with better insight into load test performance, Edamame can increase observability. Currently, visibility into the health of load generators can be ascertained by installing a Kubernetes Dashboard.<sup id="fnref-32"><a href="#fn-32" class="footnote-ref">32</a></sup></p><p>Rather than relying on additional third-party resources, in the future Edamame should provide metrics like CPU consumption, RAM consumption, and bandwidth for load generators. This would allow the user to tailor how load generating infrastructure is set up in a way that&#x27;s more specific to the tests they are running.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="c-data-import-and-export">c. Data import and export<a href="#c-data-import-and-export" class="hash-link" aria-label="Direct link to c. Data import and export" title="Direct link to c. Data import and export">​</a></h3><p>Edamame provides users with an <code>edamame teardown</code> command which deletes all associated AWS resources, including historical data. This means that data is not persisted beyond the lifecycle of the EKS cluster that supports Edamame’s architecture. We&#x27;d like to give users a way to export data when removing AWS resources, to decrease vendor lock-in.</p><p>As Edamame contains a separate backend API for the database in the form of an Express app, components are already in place to provide this service. To perform the export, one approach would be to create an SQL file representing all the data in the database, which could be downloaded to the user&#x27;s local system. This file could then be used to load the data into another database of the user&#x27;s choosing.</p><p>This approach would also enable Edamame to check for the presence of such a file during the initialization process, and use it to populate the database with the previous cluster&#x27;s data. This would ensure that data is persisted across cluster lifecycles, should the user ever need to take down their EKS infrastructure for any reason.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="11-resources">11. Resources<a href="#11-resources" class="hash-link" aria-label="Direct link to 11. Resources" title="Direct link to 11. Resources">​</a></h2><div class="footnotes"><hr><ol><li id="fn-1">Nguyen, Britney. “Ticketmaster expected 1.5 million &#x27;verified&#x27; Taylor Swift fans on the site but 14 million people were trying to get tickets, Live Nation chairman says: &#x27;We could have filled 900 stadiums&#x27;.” <em>Insider</em>, 17 Nov. 2022, <a href="https://www.businessinsider.com/ticketmaster-14-million-people-tried-buy-taylor-swift-presale-tickets-2022-11" target="_blank" rel="noopener noreferrer">https://www.businessinsider.com/ticketmaster-14-million-people-tried-buy-taylor-swift-presale-tickets-2022-11</a><a href="#fnref-1" class="footnote-backref">↩</a></li><li id="fn-2"><code>Wrk</code> is an HTTP benchmarking tool written in C known for efficiency. See repo at: <a href="https://github.com/wg/wrk" target="_blank" rel="noopener noreferrer">https://github.com/wg/wrk</a><a href="#fnref-2" class="footnote-backref">↩</a></li><li id="fn-3">k6 benchmarking results for EC2 instance type <code>m5.large</code> <a href="https://github.com/grafana/k6-benchmarks/tree/master/results/v0.42.0#ec2-m5large" target="_blank" rel="noopener noreferrer">https://github.com/grafana/k6-benchmarks/tree/master/results/v0.42.0#ec2-m5large</a><a href="#fnref-3" class="footnote-backref">↩</a></li><li id="fn-4">Lönn, Ragnar. &quot;Open source load testing tool review 2020.&quot; <em>k6 Blog</em>, 3 Mar. 2020, <a href="https://k6.io/blog/comparing-best-open-source-load-testing-tools/#memory-usage-per-vu-level" target="_blank" rel="noopener noreferrer">https://k6.io/blog/comparing-best-open-source-load-testing-tools/#memory-usage-per-vu-level</a><a href="#fnref-4" class="footnote-backref">↩</a></li><li id="fn-5">AWS product details for M5 EC2 instance types <a href="https://aws.amazon.com/ec2/instance-types/m5/" target="_blank" rel="noopener noreferrer">https://aws.amazon.com/ec2/instance-types/m5/</a><a href="#fnref-5" class="footnote-backref">↩</a></li><li id="fn-6">Ably. &quot;What it takes to build a realtime chat or messaging app.&quot; <em>Ably Blog</em>, 23 Mar. 2023, <a href="https://ably.com/blog/what-it-takes-to-build-a-realtime-chat-or-messaging-app" target="_blank" rel="noopener noreferrer">https://ably.com/blog/what-it-takes-to-build-a-realtime-chat-or-messaging-app</a><a href="#fnref-6" class="footnote-backref">↩</a></li><li id="fn-7">Google, Inc. &quot;The WebSocket Protocol.&quot; <em>Internet Engineering Task Force</em>, Dec 2011, <a href="https://www.rfc-editor.org/rfc/rfc6455" target="_blank" rel="noopener noreferrer">https://www.rfc-editor.org/rfc/rfc6455</a><a href="#fnref-7" class="footnote-backref">↩</a></li><li id="fn-8">“Thundering herd problem.” Wikipedia, Wikimedia Foundation, 26 Nov. 2022, <a href="https://en.wikipedia.org/wiki/Thundering_herd_problem" target="_blank" rel="noopener noreferrer">https://en.wikipedia.org/wiki/Thundering_herd_problem</a><a href="#fnref-8" class="footnote-backref">↩</a></li><li id="fn-9">Necheukhin, Anton. &quot;Reliable load testing with regards to unexpected nuances.&quot; <em>Medium</em>, 29 Apr. 2020, <a href="https://medium.com/miro-engineering/reliable-load-testing-with-regards-to-unexpected-nuances-6f38c82196a5" target="_blank" rel="noopener noreferrer">https://medium.com/miro-engineering/reliable-load-testing-with-regards-to-unexpected-nuances-6f38c82196a5</a><a href="#fnref-9" class="footnote-backref">↩</a></li><li id="fn-10">Ramesh, Shreya. &quot;Load Testing with Koi Pond.&quot; <em>Slack Engineering Blog</em>, Apr. 2022, <a href="https://slack.engineering/load-testing-with-koi-pond/" target="_blank" rel="noopener noreferrer">https://slack.engineering/load-testing-with-koi-pond/</a><a href="#fnref-10" class="footnote-backref">↩</a></li><li id="fn-11">k6. &quot;Load testing websites&quot; <em>k6 Documentation</em>, <a href="https://k6.io/docs/testing-guides/load-testing-websites/#execution-considerations" target="_blank" rel="noopener noreferrer">https://k6.io/docs/testing-guides/load-testing-websites/#execution-considerations</a><a href="#fnref-11" class="footnote-backref">↩</a></li><li id="fn-12">“Batch Processing vs Real Time Data Streams.” <em>Confluent</em>, <a href="https://www.confluent.io/learn/batch-vs-real-time-data-processing/" target="_blank" rel="noopener noreferrer">https://www.confluent.io/learn/batch-vs-real-time-data-processing/</a><a href="#fnref-12" class="footnote-backref">↩</a></li><li id="fn-13">Apache Software Foundation. &quot;Apache JMeter Distributed Testing Step-by-step.&quot; <em>JMeter User Manual</em>, <a href="https://jmeter.apache.org/usermanual/jmeter_distributed_testing_step_by_step.html" target="_blank" rel="noopener noreferrer">https://jmeter.apache.org/usermanual/jmeter_distributed_testing_step_by_step.html</a><a href="#fnref-13" class="footnote-backref">↩</a></li><li id="fn-14">Dingler, Lee, Lenz, Lopez, McGill, Nightingale. &quot;Distributed Load Testing on AWS Implementation Guide.&quot; <em>Amazon Web Services, Inc.</em>, Mar. 2023, <a href="https://docs.aws.amazon.com/pdfs/solutions/latest/distributed-load-testing-on-aws/distributed-load-testing-on-aws.pdf" target="_blank" rel="noopener noreferrer">https://docs.aws.amazon.com/pdfs/solutions/latest/distributed-load-testing-on-aws/distributed-load-testing-on-aws.pdf</a><a href="#fnref-14" class="footnote-backref">↩</a></li><li id="fn-15">Google Cloud. &quot;Distributed load testing using Google Kubernetes Engine.&quot; <em>Cloud Architecture Center Documentation</em>, 22 Apr. 2022, <a href="https://cloud.google.com/architecture/distributed-load-testing-using-gke" target="_blank" rel="noopener noreferrer">https://cloud.google.com/architecture/distributed-load-testing-using-gke</a><a href="#fnref-15" class="footnote-backref">↩</a></li><li id="fn-16">Pricing sources for various cloud testing tools: k6 (<a href="https://k6.io/pricing/" target="_blank" rel="noopener noreferrer">https://k6.io/pricing/</a>), Grafana Cloud (<a href="https://grafana.com/pricing/?pg=k6-cloud&amp;plcmt=pricing-details" target="_blank" rel="noopener noreferrer">https://grafana.com/pricing/?pg=k6-cloud&amp;plcmt=pricing-details</a>), BlazeMeter (<a href="https://www.blazemeter.com/pricing" target="_blank" rel="noopener noreferrer">https://www.blazemeter.com/pricing</a>), Artillery (<a href="https://www.artillery.io/pricing" target="_blank" rel="noopener noreferrer">https://www.artillery.io/pricing</a>), Gatling (<a href="https://gatling.io/pricing/#cloud-monthly" target="_blank" rel="noopener noreferrer">https://gatling.io/pricing/#cloud-monthly</a>)<a href="#fnref-16" class="footnote-backref">↩</a></li><li id="fn-17">Miric, Ivan. &quot;Testing without limits: xk6 and k6 extensions.&quot; <em>k6 Blog</em>, 2 Dec. 2020, <a href="https://k6.io/blog/extending-k6-with-xk6/#how-xk6-works" target="_blank" rel="noopener noreferrer">https://k6.io/blog/extending-k6-with-xk6/#how-xk6-works</a><a href="#fnref-17" class="footnote-backref">↩</a></li><li id="fn-18">Artillery. &quot;Distributed tests on AWS Lambda.&quot; <em>Artillery Documentation</em>, <a href="https://www.artillery.io/docs/guides/guides/distributed-load-tests-on-aws-lambda" target="_blank" rel="noopener noreferrer">https://www.artillery.io/docs/guides/guides/distributed-load-tests-on-aws-lambda</a><a href="#fnref-18" class="footnote-backref">↩</a></li><li id="fn-19">Locust. “Distributed load generation.” <em>Locust Documentation</em>, <a href="https://docs.locust.io/en/stable/running-distributed.html" target="_blank" rel="noopener noreferrer">https://docs.locust.io/en/stable/running-distributed.html</a><a href="#fnref-19" class="footnote-backref">↩</a></li><li id="fn-20">Kubernetes. “Overview.” <em>Kubernetes Documentation</em>, <a href="https://kubernetes.io/docs/concepts/overview/" target="_blank" rel="noopener noreferrer">https://kubernetes.io/docs/concepts/overview/</a><a href="#fnref-20" class="footnote-backref">↩</a></li><li id="fn-21">Deng, Głąb, Jones, Kahandi, Kantrowitz, Kinsella, Martin, Messer, Pellegrini, Schuetz, Seader, Strejevitch. &quot;CNCF Operator <!-- -->[White Paper]<!-- -->.&quot; Cloud Native Computing Foundation, Jul. 2021, <a href="https://www.cncf.io/wp-content/uploads/2021/07/CNCF_Operator_WhitePaper.pdf" target="_blank" rel="noopener noreferrer">https://www.cncf.io/wp-content/uploads/2021/07/CNCF_Operator_WhitePaper.pdf</a><a href="#fnref-21" class="footnote-backref">↩</a></li><li id="fn-22">Aronsson, Simon and Olha Yevtushenko. “Running distributed k6 tests on Kubernetes.” <em>K6 Blog</em>, 23 Jun. 2022, <a href="https://k6.io/blog/running-distributed-tests-on-k8s/" target="_blank" rel="noopener noreferrer">https://k6.io/blog/running-distributed-tests-on-k8s/</a><a href="#fnref-22" class="footnote-backref">↩</a></li><li id="fn-23">k6 benchmarking results for EC2 instance type <code>m5.24xlarge</code> <a href="https://github.com/grafana/k6-benchmarks/tree/master/results/v0.42.0#rps-optimizedjs" target="_blank" rel="noopener noreferrer">https://github.com/grafana/k6-benchmarks/tree/master/results/v0.42.0#rps-optimizedjs</a><a href="#fnref-23" class="footnote-backref">↩</a></li><li id="fn-24">k6. &quot;Running large tests.&quot; <em>k6 Documentation</em>, <a href="https://k6.io/docs/testing-guides/running-large-tests/" target="_blank" rel="noopener noreferrer">https://k6.io/docs/testing-guides/running-large-tests/</a><a href="#fnref-24" class="footnote-backref">↩</a></li><li id="fn-25">Freedman, Mike and Erik Nordström. &quot;Building a distributed time-series database on PostgreSQL.&quot; <em>Timescale Blog</em>, 21 Aug. 2019, <a href="https://www.timescale.com/blog/building-a-distributed-time-series-database-on-postgresql/" target="_blank" rel="noopener noreferrer">https://www.timescale.com/blog/building-a-distributed-time-series-database-on-postgresql/</a><a href="#fnref-25" class="footnote-backref">↩</a></li><li id="fn-26">Malpass, Ian. &quot;Measure Anything, Measure Everything.&quot; <em>Etsy: Code as Craft</em>, 11 Feb. 2015, <a href="https://www.etsy.com/codeascraft/measure-anything-measure-everything" target="_blank" rel="noopener noreferrer">https://www.etsy.com/codeascraft/measure-anything-measure-everything</a><a href="#fnref-26" class="footnote-backref">↩</a></li><li id="fn-27">&quot;The main reason being that StatsD will max out at about 10K OPS (unless they&#x27;ve improved it recently) whereas Statsite will reach 10 MM. Also, look at the difference between the implementation of sets. StatsD uses a JS object versus statsite using a C implementation of HyperLogLog. If you&#x27;re doing anything significant, you should not be using the node.js version of StatsD.&quot; Aimonetti, Matt. &quot;Practical Guide to StatsD/Graphite Monitoring.&quot; <em>Y Hacker News</em>, comment by geetarista, 28 Jun. 2013, <a href="https://news.ycombinator.com/item?id=5958381" target="_blank" rel="noopener noreferrer">https://news.ycombinator.com/item?id=5958381</a><a href="#fnref-27" class="footnote-backref">↩</a></li><li id="fn-28">&quot;Count-min sketch.&quot; Wikipedia, Wikimedia Foundation, 9 Nov. 2022, <a href="https://en.wikipedia.org/wiki/Count%E2%80%93min_sketch" target="_blank" rel="noopener noreferrer">https://en.wikipedia.org/wiki/Count%E2%80%93min_sketch</a><a href="#fnref-28" class="footnote-backref">↩</a></li><li id="fn-29">Kleppman, Martin. <em>Designing Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems.</em> &quot;O&#x27;Reilly Media, Inc.,&quot; 2017.<a href="#fnref-29" class="footnote-backref">↩</a></li><li id="fn-30">“WebSockets: Living Standard.” <em>WebSocket Specification</em>, 25 Oct. 2022, <a href="https://websockets.spec.whatwg.org/" target="_blank" rel="noopener noreferrer">https://websockets.spec.whatwg.org/</a><a href="#fnref-30" class="footnote-backref">↩</a></li><li id="fn-31">Cailliau, Pieter and Lior Kogan. &quot;t-digest: A New Probabilistic Data Structure in Redis Stack.&quot; <em>Redis Blog</em>, 14 Mar. 2023, <a href="https://redis.com/blog/t-digest-in-redis-stack/" target="_blank" rel="noopener noreferrer">https://redis.com/blog/t-digest-in-redis-stack/</a><a href="#fnref-31" class="footnote-backref">↩</a></li><li id="fn-32">Kubernetes Dashboard is a general purpose, web-based UI for Kubernetes clusters. It allows users to manage applications running in the cluster and troubleshoot them, as well as manage the cluster itself. See repo at: <a href="https://github.com/kubernetes/dashboard" target="_blank" rel="noopener noreferrer">https://github.com/kubernetes/dashboard</a><a href="#fnref-32" class="footnote-backref">↩</a></li></ol></div></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-what-is-edamame" class="table-of-contents__link toc-highlight">1. What is Edamame?</a></li><li><a href="#2-background-load-testing" class="table-of-contents__link toc-highlight">2. Background: Load testing</a><ul><li><a href="#a-what-is-load-testing" class="table-of-contents__link toc-highlight">a. What is load testing?</a></li><li><a href="#b-considerations-when-building-a-load-tester" class="table-of-contents__link toc-highlight">b. Considerations when building a load tester</a><ul><li><a href="#i-scale" class="table-of-contents__link toc-highlight">i. Scale</a></li><li><a href="#ii-protocol" class="table-of-contents__link toc-highlight">ii. Protocol</a></li><li><a href="#iii-metrics" class="table-of-contents__link toc-highlight">iii. Metrics</a></li><li><a href="#iv-visualization" class="table-of-contents__link toc-highlight">iv. Visualization</a></li></ul></li><li><a href="#c-summary" class="table-of-contents__link toc-highlight">c. Summary</a></li></ul></li><li><a href="#3-background-real-time-collaboration-apps" class="table-of-contents__link toc-highlight">3. Background: Real-time collaboration apps</a><ul><li><a href="#a-what-are-real-time-collaboration-apps" class="table-of-contents__link toc-highlight">a. What are real-time collaboration apps?</a></li><li><a href="#b-considerations-when-developing-a-collaboration-app" class="table-of-contents__link toc-highlight">b. Considerations when developing a collaboration app</a><ul><li><a href="#i-websocket-performance" class="table-of-contents__link toc-highlight">i. WebSocket performance</a></li><li><a href="#ii-supporting-separate-protocols" class="table-of-contents__link toc-highlight">ii. Supporting separate protocols</a></li><li><a href="#iii-fan-out-messaging-pattern" class="table-of-contents__link toc-highlight">iii. Fan-out messaging pattern</a></li></ul></li><li><a href="#c-summary-1" class="table-of-contents__link toc-highlight">c. Summary</a></li></ul></li><li><a href="#4-load-testing-for-collaboration-apps" class="table-of-contents__link toc-highlight">4. Load testing for collaboration apps</a><ul><li><a href="#a-generating-http-and-websocket-traffic" class="table-of-contents__link toc-highlight">a. Generating HTTP and WebSocket traffic</a></li><li><a href="#b-scaling-to-100k-concurrent-users" class="table-of-contents__link toc-highlight">b. Scaling to 100K+ concurrent users</a></li><li><a href="#c-collecting-and-displaying-data-in-near-real-time" class="table-of-contents__link toc-highlight">c. Collecting and displaying data in near real-time</a></li></ul></li><li><a href="#5-existing-solutions" class="table-of-contents__link toc-highlight">5. Existing solutions</a><ul><li><a href="#a-diy" class="table-of-contents__link toc-highlight">a. DIY</a></li><li><a href="#b-managed-cloud-based-services" class="table-of-contents__link toc-highlight">b. Managed cloud-based services</a></li><li><a href="#c-an-in-between" class="table-of-contents__link toc-highlight">c. An in-between</a></li></ul></li><li><a href="#6-edamame-architecture" class="table-of-contents__link toc-highlight">6. Edamame architecture</a></li><li><a href="#7-building-edamame-load-generation" class="table-of-contents__link toc-highlight">7. Building Edamame: Load Generation</a><ul><li><a href="#a-scaling-to-100k-virtual-users" class="table-of-contents__link toc-highlight">a. Scaling to 100k+ virtual users</a></li><li><a href="#b-synchronizing-load-generators" class="table-of-contents__link toc-highlight">b. Synchronizing load generators</a></li><li><a href="#c-optimizing-compute-resources" class="table-of-contents__link toc-highlight">c. Optimizing compute resources</a></li></ul></li><li><a href="#8-building-edamame-data-handling" class="table-of-contents__link toc-highlight">8. Building Edamame: Data Handling</a><ul><li><a href="#a-processing-1m-data-points-per-second" class="table-of-contents__link toc-highlight">a. Processing 1M data points per second</a></li><li><a href="#b-stream-processing-pipeline" class="table-of-contents__link toc-highlight">b. Stream processing pipeline</a></li></ul></li><li><a href="#9-building-edamame-data-visualization" class="table-of-contents__link toc-highlight">9. Building Edamame: Data Visualization</a><ul><li><a href="#a-extracting-meaningful-insights" class="table-of-contents__link toc-highlight">a. Extracting meaningful insights</a></li><li><a href="#b-building-a-custom-k6-extension" class="table-of-contents__link toc-highlight">b. Building a custom k6 extension</a></li></ul></li><li><a href="#10-future-plans" class="table-of-contents__link toc-highlight">10. Future plans</a><ul><li><a href="#a-improving-scalability" class="table-of-contents__link toc-highlight">a. Improving scalability</a></li><li><a href="#b-increased-observability" class="table-of-contents__link toc-highlight">b. Increased observability</a></li><li><a href="#c-data-import-and-export" class="table-of-contents__link toc-highlight">c. Data import and export</a></li></ul></li><li><a href="#11-resources" class="table-of-contents__link toc-highlight">11. Resources</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.75d44608.js"></script>
<script src="/assets/js/main.3bbd35a5.js"></script>
</body>
</html>